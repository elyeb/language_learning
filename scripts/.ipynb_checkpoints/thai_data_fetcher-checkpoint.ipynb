{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aba0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Contents:\n",
    "-data intialization from csv file of words &\n",
    " build data structure to house info moving forward\n",
    "-write to .json formats\n",
    "-read from existing .json formats\n",
    "-get list of words to find\n",
    "-scrape BBC\n",
    "-scrape voiceTV\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdc6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state Washington server backend.\n"
     ]
    }
   ],
   "source": [
    "import bs4, requests, sys, codecs, urllib.request, re\n",
    "from bs4 import SoupStrainer\n",
    "from bs4.element import Comment\n",
    "import random\n",
    "#import pythainlp\n",
    "from pythainlp.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pprint\n",
    "import translators as ts\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "path = \"/Users/elyebliss/Desktop/Vocabulary/language_learning/vocab_dfs/\"\n",
    "source_file = \"thai.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce69b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##METHODS\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = bs4.BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 6.3; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'\n",
    "headers={'User-Agent':user_agent,}\n",
    "parser = 'html.parser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63afba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_known(unknown_list):\n",
    "    \n",
    "    count_got = 0\n",
    "    known_list = []\n",
    "    for word in unknown_list:\n",
    "        decision = str(input(word+\"\\nKnown =k\"))\n",
    "        if decision =='k':\n",
    "            known_list.append(word)\n",
    "            count_got +=1\n",
    "            print(\"got \"+str(count_got))\n",
    "        elif decision=='q':\n",
    "            break\n",
    "        try:\n",
    "            print(ts.google(word))\n",
    "        except:\n",
    "            print('cant find')\n",
    "    return known_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117b26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(webpage,start=None,stop=None,\\\n",
    "                print_word_lvl=False,percent_threshold=None,\\\n",
    "               return_percent=False):\n",
    "\n",
    "\n",
    "    try:\n",
    "        request=urllib.request.Request(webpage,None,headers) #The assembled request\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "\n",
    "        known_array = []\n",
    "        unk_array = []\n",
    "        contents_array = sent_tokenize(contents)\n",
    "\n",
    "        if (start is not None) and (stop is not None):\n",
    "            contents_array=contents_array[max(start,0):min(stop,len(contents_array))]\n",
    "\n",
    "        disallowed_words = set()\n",
    "\n",
    "        total_words = 0\n",
    "        unknown_words = 0\n",
    "        \n",
    "        lines = []\n",
    "        unknowns = []\n",
    "        for line in contents_array:\n",
    "\n",
    "\n",
    "            tokenized = word_tokenize(line)\n",
    "\n",
    "\n",
    "            add_line = True\n",
    "            line_total = 0\n",
    "            line_unks = 0\n",
    "\n",
    "            unk_str = \"\"\n",
    "            for word in tokenized:\n",
    "                \n",
    "                total_words +=1\n",
    "                line_total +=1\n",
    "\n",
    "                if bool(re.search('[\\u0E00-\\u0E7F]+', word, flags=re.UNICODE)) and not ((word in vocab['white_listed']) or\\\n",
    "                                                            (word in vocab['black_listed'])):\n",
    "\n",
    "                        unk_str += '\"'+word+'\"'+\", \"\n",
    "                        if not percent_threshold:\n",
    "                            add_line = False\n",
    "                        disallowed_words.add(word)\n",
    "                        unknown_words +=1\n",
    "                        line_unks +=1\n",
    "\n",
    "            if percent_threshold:\n",
    "                if line_total>0:\n",
    "                    if (1-(line_unks/line_total))<percent_threshold:\n",
    "                        add_line = False\n",
    "            if add_line:\n",
    "                known_array.append(line)\n",
    "                unk_array.append(\"...\")\n",
    "            else:\n",
    "                known_array.append(\"...\")\n",
    "                unk_array.append(line)\n",
    "\n",
    "            if len(unk_str)>0:\n",
    "                unk_str = unk_str[0:len(unk_str)-2]\n",
    "\n",
    "            unknowns.append(unk_str)\n",
    "\n",
    "        if print_word_lvl and total_words>0:\n",
    "            print(\"word-level % known = \"+str((1-(unknown_words/total_words))*100))\n",
    "        if return_percent and total_words>0:\n",
    "            return (1-(unknown_words/total_words))*100\n",
    "        return_pd = pd.DataFrame(list(zip(known_array,unk_array,unknowns)))\n",
    "        return_pd.columns = [\"knowns\",\"unknowns\",\"unk_words\"]\n",
    "\n",
    "        \n",
    "\n",
    "        with open(path+'unknown_thai_list.txt',\"w\") as outfile:\n",
    "            outfile.write(str(list(disallowed_words)))\n",
    "\n",
    "        return return_pd\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "826dae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2164\n",
      "2543\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read from existing .json formats\n",
    "uncovered, \n",
    "2164\n",
    "2543\n",
    "\"\"\"\n",
    "with open(path+source_file, \"r\") as path_in:\n",
    "    vocab = json.loads(path_in.read())\n",
    "vocab['white_listed'] = set(vocab['white_listed'])\n",
    "vocab['black_listed'] = set(vocab['black_listed'])\n",
    "print(len(vocab['white_listed'])) \n",
    "\n",
    "#get 4k freq word info:\n",
    "with open(path+'th_freq.csv','r') as infile:\n",
    "    freq_df = pd.read_csv(infile)\n",
    "uncovered = []\n",
    "for word in freq_df.word:\n",
    "    if word not in vocab['white_listed']:\n",
    "        uncovered.append(word)\n",
    "print(len(uncovered))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004a939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking BBC Thai\n",
      "Checking VoiceTV\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "titles = []\n",
    "\n",
    "##BBC\n",
    "print(\"Checking BBC Thai\")\n",
    "parser = 'html.parser'  # or 'lxml' (preferred) or 'html5lib', if installed\n",
    "request=urllib.request.Request('https://www.bbc.com/thai/topics/cjgn73g98rqt',None,headers)\n",
    "resp = urllib.request.urlopen(request)\n",
    "soup = bs4.BeautifulSoup(resp, parser, from_encoding=resp.info().get_param('charset'))\n",
    "\n",
    "\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if 'https://www.bbc.com/thai/thailand' in str(link['href']):\n",
    "        pages.append(str(link['href']))\n",
    "        request=urllib.request.Request(str(link['href']),None,headers) #The assembled request\n",
    "\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "        if bool(re.search(\"(?<=ยอดนิยม หน้าแรก ประเทศไทย ต่างประเทศ วิทยาศาสตร์ สุขภาพ โควิด-19 วิดีโอ ยอดนิยม).{30}\",contents)):\n",
    "            titles.append(re.findall(\"(?<=ยอดนิยม หน้าแรก ประเทศไทย ต่างประเทศ วิทยาศาสตร์ สุขภาพ โควิด-19 วิดีโอ ยอดนิยม).{30}\",contents)[0].strip())\n",
    "\n",
    "    elif '/thai/thailand' in str(link['href']):\n",
    "        pages.append('https://www.bbc.com'+str(link['href']))\n",
    "\n",
    "##VoiceTV\n",
    "print(\"Checking VoiceTV\")\n",
    "parser = 'html.parser'  # or 'lxml' (preferred) or 'html5lib', if installed\n",
    "request=urllib.request.Request('https://www.voicetv.co.th/topic/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B9%80%E0%B8%A1%E0%B8%B7%E0%B8%AD%E0%B8%87',None,headers)\n",
    "resp = urllib.request.urlopen(request)\n",
    "soup = bs4.BeautifulSoup(resp, parser, from_encoding=resp.info().get_param('charset'))\n",
    "\n",
    " \n",
    "for link in soup.find_all('a', href=True):\n",
    "    str_page = 'https://www.voicetv.co.th'+str(link['href'])\n",
    "    if '/read/' in str(link['href']) and str_page not in pages:\n",
    "        pages.append(str_page)\n",
    "        request=urllib.request.Request(str_page,None,headers) #The assembled request\n",
    "\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "        titles.append(re.findall(\"(?<=  :).{30}\",contents)[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load prev corpus and add\n",
    "known_corpus = set()\n",
    "with open(path+\"all_known_thai_lines.txt\",\"r\",encoding='utf-8') as infile:\n",
    "    for line in infile.read().split('\\n'):\n",
    "        known_corpus.add(line)\n",
    "len(known_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6ee0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent all known= 0.1476725521669342\n"
     ]
    }
   ],
   "source": [
    "#Find % of all sentences of news\n",
    "knowns = []\n",
    "all_lines = 0\n",
    "\n",
    "known_percents = []\n",
    "\n",
    "for webpage in pages:\n",
    "    \n",
    "    test_df = filter_text(webpage)\n",
    "    all_lines += len(list(test_df.knowns))\n",
    "    \n",
    "    known_percents.append(filter_text(webpage,return_percent=True))\n",
    "    \n",
    "    for item in list(test_df.knowns[test_df.knowns != '...']):\n",
    "        knowns.append(item)\n",
    "percent = len(knowns)/float(all_lines)\n",
    "print(\"percent all known= \"+str(percent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa348ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ดังนั้นสามารถพูดได้ทุกอย่าง อย่างเต็มที่ ยืนยัน การเมืองไม่ใช่อนาคตของตนเอง ',\n",
       " 'ซึ่งหากมีการพูดคุยกันภายในฝั่งเจ้าหน้าที่ตำรวจคงจะไม่เกิดเหตุการณ์นั้นเลย ',\n",
       " 'ไม่ใช่เมื่อถึงเวลาก็สามารถนำกำลังเข้ามาทำร้ายได้เลย ',\n",
       " 'โดยผู้ชุมนุมขอว่าหากไปต่อไม่ได้ก็จะอยู่ตรงนี้ไปก่อน ',\n",
       " 'ท่านมีจิตใจที่จะทำงานเพื่อสังคม แต่ไฟผมหมดแล้ว ',\n",
       " 'Last update Nov 24, 2022 14:50 )   ‘สมหญิง’ ',\n",
       " 'คนที่ 10 เมื่อ 7 ชั่วโมงที่แล้ว ',\n",
       " 'เพราะหาก ท้องถิ่นจะเปิดสอบเอง ',\n",
       " 'ส.ส.อำนาจฯ Nov 24, 2022 ( ',\n",
       " 'และเห็นว่า บางตำแหน่ง ',\n",
       " 'ท้องถิ่นไม่ควรทำเอง ',\n",
       " 'ไม่ถึง 30 ล้านบาท ',\n",
       " 'สังคมจะรับไม่ได้ ',\n",
       " 'หน่วยงานของตนเอง ',\n",
       " 'หากเกินกว่านี้ ',\n",
       " 'ในวันดังกล่าว ',\n",
       " 'ทำให้ดีที่สุด ',\n",
       " 'ให้ท่านทำไป ',\n",
       " 'ตรวจสอบได้ ',\n",
       " 'ก็ดูแลด้วย ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(list(set(knowns)),key=len,reverse=True)\n",
    "sorted(list(set(knowns).difference(known_corpus)),key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee450fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in list(set(knowns)):\n",
    "    known_corpus.add(item)\n",
    "\n",
    "with open(path+\"all_known_thai_lines.txt\",\"w\",encoding='utf-8') as outfile:\n",
    "    for line in list(set(known_corpus)):\n",
    "        outfile.write(line+'\\n')\n",
    "len(known_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6948c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "websites = set()\n",
    "\n",
    "with open(path+'viewed_websites_th.txt',\"r\") as infile:\n",
    "    for line in infile.read().split('\\n'):\n",
    "        websites.add(line)\n",
    "print(len(websites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a643828",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  87.88426763110307,\n",
       "  \"'กมธ.พัฒนาการเมืองฯ' เชิญ 'รา\",\n",
       "  'https://www.voicetv.co.th/read/9OrSFO8wi'),\n",
       " (5,\n",
       "  87.40416210295729,\n",
       "  '‘วิษณุ’แย้มประตูยุบสภาเปิดอยู',\n",
       "  'https://www.voicetv.co.th/read/WRfVuH5Ed'),\n",
       " (3,\n",
       "  86.46288209606988,\n",
       "  '‘จิราพร’ ให้ ‘ประยุทธ์’ สอบตก',\n",
       "  'https://www.voicetv.co.th/read/ZKWwEQwfG'),\n",
       " (4,\n",
       "  86.2240663900415,\n",
       "  '‘ประยุทธ์’ อวยพรปีใหม่สื่อทำเ',\n",
       "  'https://www.voicetv.co.th/read/YSRkY2I1d'),\n",
       " (0,\n",
       "  85.68738229755179,\n",
       "  '‘สมหญิง’พร้อมสู้คดีฟุตซอล ยัน',\n",
       "  'https://www.bbc.com/thai/thailand-63662204'),\n",
       " (1,\n",
       "  81.8326439707286,\n",
       "  \"'อนุพงษ์' พบผู้บริหาร อบต. ทั\",\n",
       "  'https://www.bbc.com/thai/thailand-63566397'),\n",
       " (6,\n",
       "  80.27923211169285,\n",
       "  \"รีวิว 'Collective': นักข่าวไม\",\n",
       "  'https://www.voicetv.co.th/read/bn95YMr0a')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_titles = list(zip(range(0,len(known_percents)),known_percents,titles,pages))\n",
    "# (sorted(list(zip(range(0,len(known_percents)),known_percents)),key = lambda x: x[1],reverse=True))\n",
    "page_titles = sorted(page_titles,key = lambda x: x[1],reverse=True)\n",
    "page_titles = [item for item in page_titles if not (item[3] in websites)]\n",
    "page_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e2e7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = pages[2]\n",
    "if webpage in websites:\n",
    "    print(\"already scanned! choose another!\")\n",
    "websites.add(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f737a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(path+'viewed_websites_th.txt',\"w\") as outfile:\n",
    "    for line in websites:\n",
    "        outfile.write(line+'\\n')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "141ae514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word-level % known = 87.88426763110307\n"
     ]
    }
   ],
   "source": [
    "#display() #percent_threshold=0.95\n",
    "art=filter_text(webpage,print_word_lvl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bce1137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "with open(path+'unknown_thai_list.txt',\"r\") as input_file:\n",
    "    new_words = input_file.read()\n",
    "    new_words = re.sub(\"[\\n\\'\\[\\]]\",\"\",new_words)\n",
    "    new_words = new_words.split(',')\n",
    "    new_words = [line.strip() for line in new_words] #update regex\n",
    "#new_words\n",
    "print(len(new_words))\n",
    "#known_manual = get_known(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd86a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitosheet\n",
    "unk_df = pd.DataFrame(new_words)\n",
    "unk_df.columns = ['word']\n",
    "unk_df['status'] = pd.Series(['' for word in new_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3663bb4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f366a78278844edbb8ef149c8a5e95b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MitoWidget(analysis_data_json='{\"analysisName\": \"id-bzlqgvmqzj\", \"analysisToReplay\": null, \"code\": [], \"stepSu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mitosheet.sheet(unk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60d5d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ints = [20, 28, 33, 37, 42, 44, 45, 48, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77eb121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in add_ints:\n",
    "    # Set a cell value in status\n",
    "    unk_df.at[i, 'status'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71c577e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "for i in range(0,len(unk_df)):\n",
    "    try:\n",
    "        translations.append(ts.google(unk_df.word.iloc[i]))\n",
    "    except:\n",
    "        translations.append('')\n",
    "unk_df['translations']=translations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe5bce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b33965d4274f1092184b7dac6d2270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MitoWidget(analysis_data_json='{\"analysisName\": \"id-cofchfkpsa\", \"analysisToReplay\": null, \"code\": [], \"stepSu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mitosheet.sheet(unk_df, analysis_to_replay=\"id-cofchfkpsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8a5ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "455c3cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "add_words = list(unk_df.word[unk_df['status']=='k'])\n",
    "print(len(add_words))\n",
    "for word in add_words:\n",
    "    vocab['white_listed'].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27b8e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually remove from white\n",
    "remove_from_white = []\n",
    "\n",
    "for word in remove_from_white:\n",
    "    if word in vocab['white_listed']:\n",
    "        vocab['white_listed'].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2706f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually add to white\n",
    "add_to_white = []\n",
    "\n",
    "for word in add_to_white:\n",
    "    vocab['white_listed'].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02a15572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2164\n"
     ]
    }
   ],
   "source": [
    "#write to .json formats\n",
    "df = vocab\n",
    "df['white_listed'] = list(df['white_listed'])\n",
    "df['black_listed'] = list(df['black_listed'])\n",
    "with open(path+source_file, \"w\") as outfile:\n",
    "    json.dump(df,outfile)\n",
    "print(len(df['white_listed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7f67a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2164\n"
     ]
    }
   ],
   "source": [
    "#read from existing .json formats\n",
    "with open(path+source_file, \"r\") as path_in:\n",
    "    vocab = json.loads(path_in.read())\n",
    "vocab['white_listed'] = set(vocab['white_listed'])\n",
    "vocab['black_listed'] = set(vocab['black_listed'])\n",
    "print(len(vocab['white_listed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f09c08d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.voicetv.co.th/read/9OrSFO8wi\n",
      "word-level % known = 90.23508137432188\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div id=9bfad407-67a3-451e-95ee-006592c657fe style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('9bfad407-67a3-451e-95ee-006592c657fe').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowns</th>\n",
       "      <th>unknowns</th>\n",
       "      <th>unk_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS LIVE POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS ABOUT FAQ CONTACT TERM OF USE SCHEDULE ไม่พบผลการค้นหา</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>คุณกำลังอ่าน  : ‘สมหญิง’พร้อมสู้คดีฟุตซอล</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...</td>\n",
       "      <td>ยันไม่กระทบลงชิง</td>\n",
       "      <td>\"ยัน\", \"ชิง\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ส.ส.อำนาจฯ Share Tweet Share การเมือง ‘สมหญิง’พร้อมสู้คดีฟุตซอล</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...</td>\n",
       "      <td>ยันไม่กระทบลงชิง</td>\n",
       "      <td>\"ยัน\", \"ชิง\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>เมื่อมีผู้มาร้องเรียนจึงต้องมีการตรวจสอบเพื่อความถูกต้อง เพื่อความสบายใจของทุกฝ่าย</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>...</td>\n",
       "      <td>“ในการลงสมัครรับเลือกตั้งนั้น ดิฉันขอยืนยันว่าลงสมัครรับเลือกตั้งได้</td>\n",
       "      <td>\"ลงสมัครรับเลือกตั้ง\", \"ลงสมัครรับเลือกตั้ง\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>...</td>\n",
       "      <td>ขอให้พี่น้องประชาชนให้กำลังใจซึ่งอาจมีบุคคลที่จ้องจะทำลายชื่อเสียง</td>\n",
       "      <td>\"จ้อง\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>...</td>\n",
       "      <td>มั่นใจว่ากรณีที่เกิดขึ้นมาไม่มีผลต่อการเป็นผู้สมัครสมาชิกสภาผู้แทนราษฎร จังหวัดอำนาจเจริญแต่อย่างใด พร้อมที่จะลงสมัคร ส.ส.เพื่อเป็นตัวเลือกให้กับประชาชนในจังหวัด พร้อมสู้ทุกกติกาและมั่นใจว่าจากผลงานที่ตนทำมาและเข้าถึงพี่น้องประชาชนมาตลอด</td>\n",
       "      <td>\"มีผลต่อ\", \"สมาชิกสภาผู้แทนราษฎร\", \"อำนาจเจริญ\", \"ลงสมัคร\", \"กติกา\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>...</td>\n",
       "      <td>ประชาชนจะยังคงเชื่อมั่นตนและพรรคเพื่อไทยอย่างแน่นอน” สมหญิง กล่าว Topic การเมือง , พรรคเพื่อไทย , คณะกรรมการป้องกันและปราบการทุจริตแห่งชาติ Author กองบรรณาธิการวอยซ์ออนไลน์ 50963 Article 1192 Video 10 Blog MOST VIEWED READ WATCH ABOUT FAQ CONTACT TERM OF USE SCHEDULE</td>\n",
       "      <td>\"เชื่อมั่น\", \"ปราบ\", \"ทุจริต\", \"กองบรรณาธิการ\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                 knowns  \\\n",
       "0      POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS LIVE POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS ABOUT FAQ CONTACT TERM OF USE SCHEDULE ไม่พบผลการค้นหา    \n",
       "1   คุณกำลังอ่าน  : ‘สมหญิง’พร้อมสู้คดีฟุตซอล                                                                                                                                                                                                             \n",
       "2   ...                                                                                                                                                                                                                                                   \n",
       "3   ส.ส.อำนาจฯ Share Tweet Share การเมือง ‘สมหญิง’พร้อมสู้คดีฟุตซอล                                                                                                                                                                                       \n",
       "4   ...                                                                                                                                                                                                                                                   \n",
       "5   ส.ส.อำนาจฯ Nov 24, 2022 (                                                                                                                                                                                                                             \n",
       "6   Last update Nov 24, 2022 14:50 )   ‘สมหญิง’                                                                                                                                                                                                           \n",
       "7   ...                                                                                                                                                                                                                                                   \n",
       "8   ...                                                                                                                                                                                                                                                   \n",
       "9   ...                                                                                                                                                                                                                                                   \n",
       "10  ...                                                                                                                                                                                                                                                   \n",
       "11  ...                                                                                                                                                                                                                                                   \n",
       "12  ตนเองไม่ได้มีส่วนเกี่ยวข้องเกี่ยวกับสนามฟุตซอลแต่อย่างใด                                                                                                                                                                                              \n",
       "13  ...                                                                                                                                                                                                                                                   \n",
       "14  ...                                                                                                                                                                                                                                                   \n",
       "15  เมื่อมีผู้มาร้องเรียนจึงต้องมีการตรวจสอบเพื่อความถูกต้อง เพื่อความสบายใจของทุกฝ่าย                                                                                                                                                                    \n",
       "16  ...                                                                                                                                                                                                                                                   \n",
       "17  ...                                                                                                                                                                                                                                                   \n",
       "18  ...                                                                                                                                                                                                                                                   \n",
       "19  ...                                                                                                                                                                                                                                                   \n",
       "\n",
       "                                                                                                                                                                                                                                                                             unknowns  \\\n",
       "0   ...                                                                                                                                                                                                                                                                                 \n",
       "1   ...                                                                                                                                                                                                                                                                                 \n",
       "2   ยันไม่กระทบลงชิง                                                                                                                                                                                                                                                                    \n",
       "3   ...                                                                                                                                                                                                                                                                                 \n",
       "4   ยันไม่กระทบลงชิง                                                                                                                                                                                                                                                                    \n",
       "5   ...                                                                                                                                                                                                                                                                                 \n",
       "6   ...                                                                                                                                                                                                                                                                                 \n",
       "7   ส.ส.อำนาจฯ พร้อมพิสูจน์ตัวเองในสนามเลือกตั้งอำนาจเจริญ น้อมรับคำสั่งศาล เผยพร้อมชี้แจงทุกเรื่องเชื่อความยุติธรรมมีจริง                                                                                                                                                              \n",
       "8   วันที่ 24 พ.ย. 2565 สมหญิง บัวบุตร ส.ส.อำนาจเจริญ พรรคเพื่อไทย เปิดเผยว่าจากกรณีที่ถูกคณะกรรมการป้องกันและปราบปรามการทุจริตแห่งชาติ หรือป.ป.ช.                                                                                                                                      \n",
       "9   ยื่นฟ้องศาลฎีกา เเผนกคดีอาญาผู้ดำรงตำเเหน่งทางการเมือง ตามขั้นตอนทางกฎหมาย โดยอัยการสูงสุดได้ยื่นฟ้องตนเอง กับ พวกรวม 12 คน เป็นจําเลยต่อศาลฎีกาแผนกคดีอาญาของผู้ดำรงตำแหน่งทางการเมือง ทั้งนี้เมื่อศาลประทับรับฟ้องและมีคำสั่งใหตนหยุดปฏิบัติหน้าที่เป็นเรื่องปกติ                 \n",
       "10  เมื่อเข้าสู่กระบวนการทางศาลกลับดีใจด้วยซ้ำที่มีโอกาสที่จะชี้แจงข้อเท็จจริงต่อศาล แต่ยังคงเป็น ส.ส.สามารถปฏิบัติหน้าที่ช่วยเหลือพี่น้องประชาชนในนามคณะกรรมาธิการได้ต่อไป                                                                                                             \n",
       "11  สมหญิง กล่าวด้วยว่าในส่วนคดี ตนเชื่อมั่นว่าจะได้รับความเป็นธรรม                                                                                                                                                                                                                     \n",
       "12  ...                                                                                                                                                                                                                                                                                 \n",
       "13  และเป็นผู้นำคณะครูไปร้องเรียนที่สำนักงานตรวจเงินแผ่นดินภาค 5 จังหวัดอุบลราชธานี หรือ สตง. เป็นเหตุให้ไม่มีการเบิกจ่ายเงินงบประมาณ                                                                                                                                                   \n",
       "14  ดังนั้นเมื่อมีการนำเรื่องขึ้นสู่การพิจารณาของศาลจะได้ชี้แจงต่อศาลตามขั้นตอนกฎหมายต่อไป ซึ่งพร้อมที่จะพิสูจน์ตัวเองในฐานะผู้แทนของประชาชน                                                                                                                                            \n",
       "15  ...                                                                                                                                                                                                                                                                                 \n",
       "16  “ในการลงสมัครรับเลือกตั้งนั้น ดิฉันขอยืนยันว่าลงสมัครรับเลือกตั้งได้                                                                                                                                                                                                                \n",
       "17  ขอให้พี่น้องประชาชนให้กำลังใจซึ่งอาจมีบุคคลที่จ้องจะทำลายชื่อเสียง                                                                                                                                                                                                                  \n",
       "18  มั่นใจว่ากรณีที่เกิดขึ้นมาไม่มีผลต่อการเป็นผู้สมัครสมาชิกสภาผู้แทนราษฎร จังหวัดอำนาจเจริญแต่อย่างใด พร้อมที่จะลงสมัคร ส.ส.เพื่อเป็นตัวเลือกให้กับประชาชนในจังหวัด พร้อมสู้ทุกกติกาและมั่นใจว่าจากผลงานที่ตนทำมาและเข้าถึงพี่น้องประชาชนมาตลอด                                       \n",
       "19  ประชาชนจะยังคงเชื่อมั่นตนและพรรคเพื่อไทยอย่างแน่นอน” สมหญิง กล่าว Topic การเมือง , พรรคเพื่อไทย , คณะกรรมการป้องกันและปราบการทุจริตแห่งชาติ Author กองบรรณาธิการวอยซ์ออนไลน์ 50963 Article 1192 Video 10 Blog MOST VIEWED READ WATCH ABOUT FAQ CONTACT TERM OF USE SCHEDULE         \n",
       "\n",
       "                                                                                                                                                                               unk_words  \n",
       "0                                                                                                                                                                                         \n",
       "1                                                                                                                                                                                         \n",
       "2   \"ยัน\", \"ชิง\"                                                                                                                                                                          \n",
       "3                                                                                                                                                                                         \n",
       "4   \"ยัน\", \"ชิง\"                                                                                                                                                                          \n",
       "5                                                                                                                                                                                         \n",
       "6                                                                                                                                                                                         \n",
       "7   \"อำนาจเจริญ\", \"น้อม\", \"คำสั่งศาล\", \"ชี้แจง\", \"ความยุติธรรม\"                                                                                                                           \n",
       "8   \"บัว\", \"อำนาจเจริญ\", \"ปราบปราม\", \"ทุจริต\"                                                                                                                                             \n",
       "9   \"ยื่นฟ้อง\", \"ศาลฎีกา\", \"เผ\", \"คดีอาญา\", \"ตำ\", \"เหน่ง\", \"ขั้นตอน\", \"อัยการสูงสุด\", \"ยื่นฟ้อง\", \"ศาลฎีกา\", \"แผนก\", \"คดีอาญา\", \"ผู้ดำรงตำแหน่งทางการเมือง\", \"ประทับ\", \"รับฟ้อง\", \"ใหตน\"  \n",
       "10  \"ด้วยซ้ำ\", \"ชี้แจง\", \"ในนาม\", \"คณะกรรมาธิการ\"                                                                                                                                         \n",
       "11  \"เชื่อมั่น\", \"ความเป็นธรรม\"                                                                                                                                                           \n",
       "12                                                                                                                                                                                        \n",
       "13  \"อุบลราชธานี\", \"สตง.\", \"เป็นเหตุให้\", \"เบิก\", \"งบประมาณ\"                                                                                                                              \n",
       "14  \"ชี้แจง\", \"ขั้นตอน\"                                                                                                                                                                   \n",
       "15                                                                                                                                                                                        \n",
       "16  \"ลงสมัครรับเลือกตั้ง\", \"ลงสมัครรับเลือกตั้ง\"                                                                                                                                          \n",
       "17  \"จ้อง\"                                                                                                                                                                                \n",
       "18  \"มีผลต่อ\", \"สมาชิกสภาผู้แทนราษฎร\", \"อำนาจเจริญ\", \"ลงสมัคร\", \"กติกา\"                                                                                                                   \n",
       "19  \"เชื่อมั่น\", \"ปราบ\", \"ทุจริต\", \"กองบรรณาธิการ\"                                                                                                                                        "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(webpage)\n",
    "filter_text(webpage,print_word_lvl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bfa91",
   "metadata": {},
   "source": [
    "##END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "db36cdb8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily catch in word count:\n",
      "['เชิญ', 'ยิ้ม', 'ยินดี', 'รอย', 'เอกสาร', 'สนิท', 'กระดาษ', 'คอ', 'โรงพยาบาล', 'หิน', 'จด', 'ปืน', 'โต๊ะ', 'เสื้อผ้า', 'เลือด', 'สิทธิ์', 'นักเขียน', 'สนุกสนาน', 'หัวเราะ', 'หู', 'ยิง', 'สวยงาม', 'ล่า', 'แขก', 'ดอกไม้', 'ที่นั่ง', 'เสือ', 'ปกป้อง', 'รับประทาน', 'ไอ', 'สนุก', 'ลูกชาย', 'สหรัฐ', 'นิ้ว', 'ไอ้', 'รถไฟ', 'เล็กน้อย', 'โปรด', 'คะแนน', 'กรุณา', 'โรงแรม', 'จดหมาย', 'ขับ', 'ดื่ม', 'หอม', 'ระมัดระวัง', 'ฤดู', 'ฟัน', 'เท้า', 'หล่อน', 'วางแผน', 'ลับ', 'ลอย', 'ยกเว้น', 'ลูกค้า', 'ริม', 'ม้า', 'คอมพิวเตอร์']\n"
     ]
    }
   ],
   "source": [
    "#Upload from download\n",
    "with open(path+'known_thai_list.txt',\"r\") as input_file:\n",
    "    new_words = input_file.read().split(',')\n",
    "    print(\"daily catch in word count:\")\n",
    "    print(new_words)\n",
    "for line in new_words:   \n",
    "    vocab['white_listed'].add(line.replace(\"'\",\"\").strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0141a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Nong\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wyw_text = 'สวัสดีครับน้อง'\n",
    "print(ts.google(wyw_text))\n",
    "#print(ts._google.language_map)\n",
    "#print(ts.google(wyw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "67b1cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today's catch % of corpus:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.200344766395417%'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get after when adding in new words\n",
    "print(\"today's catch % of corpus:\")\n",
    "str(100*(percent-prev_percent))+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output newly knowns\n",
    "with open(path+\"new_known_thai_lines.txt\",\"w\") as outfile:\n",
    "    for line in list(set(knowns).difference(prev_knowns)):\n",
    "        outfile.write(line+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a9fb3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check. Current vocab size:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sanity check. Current vocab size:\")\n",
    "len(vocab['white_listed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "564b37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "to do:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9799280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##INPUT-OUTPUT\n",
    "#vocab list:\n",
    "with open(\"/Users/elyebliss/Desktop/Vocabulary/vocab_dfs/thai_whitelisted.csv\",\"r\") as infile:\n",
    "    whitelisted_lemmas = infile.read()\n",
    "\n",
    "\n",
    "##VARIABLES\n",
    "vocab_all = set()\n",
    "\n",
    "\n",
    "for line in whitelisted_lemmas.split('\\n'):\n",
    "    if len(line) > 0:\n",
    "        \n",
    "        vocab = line.strip()\n",
    "        vocab_all.add(vocab)\n",
    "        \n",
    "len(whitelisted_lemmas.split('\\n'))            \n",
    "#pp.pprint(vocab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e37bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "vocab['white_listed'] = list(vocab_all)\n",
    "vocab['black_listed'] = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
