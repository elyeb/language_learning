{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aba0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Contents:\n",
    "-data intialization from csv file of words &\n",
    " build data structure to house info moving forward\n",
    "-write to .json formats\n",
    "-read from existing .json formats\n",
    "-get list of words to find\n",
    "-scrape BBC\n",
    "-scrape voiceTV\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdc6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state Washington server backend.\n"
     ]
    }
   ],
   "source": [
    "import bs4, requests, sys, codecs, urllib.request, re\n",
    "from bs4 import SoupStrainer\n",
    "from bs4.element import Comment\n",
    "import random\n",
    "#import pythainlp\n",
    "from pythainlp.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pprint\n",
    "import translators as ts\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "path = \"/Users/elyebliss/Desktop/Vocabulary/language_learning/vocab_dfs/\"\n",
    "source_file = \"thai.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce69b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##METHODS\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = bs4.BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 6.3; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'\n",
    "headers={'User-Agent':user_agent,}\n",
    "parser = 'html.parser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63afba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_known(unknown_list):\n",
    "    \n",
    "    count_got = 0\n",
    "    known_list = []\n",
    "    for word in unknown_list:\n",
    "        decision = str(input(word+\"\\nKnown =k\"))\n",
    "        if decision =='k':\n",
    "            known_list.append(word)\n",
    "            count_got +=1\n",
    "            print(\"got \"+str(count_got))\n",
    "        elif decision=='q':\n",
    "            break\n",
    "        try:\n",
    "            print(ts.google(word))\n",
    "        except:\n",
    "            print('cant find')\n",
    "    return known_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117b26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(webpage,start=None,stop=None,\\\n",
    "                print_word_lvl=False,percent_threshold=None,\\\n",
    "               return_percent=False):\n",
    "\n",
    "\n",
    "    try:\n",
    "        request=urllib.request.Request(webpage,None,headers) #The assembled request\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "\n",
    "        known_array = []\n",
    "        unk_array = []\n",
    "        contents_array = sent_tokenize(contents)\n",
    "\n",
    "        if (start is not None) and (stop is not None):\n",
    "            contents_array=contents_array[max(start,0):min(stop,len(contents_array))]\n",
    "\n",
    "        disallowed_words = set()\n",
    "\n",
    "        total_words = 0\n",
    "        unknown_words = 0\n",
    "        \n",
    "        lines = []\n",
    "        unknowns = []\n",
    "        for line in contents_array:\n",
    "\n",
    "\n",
    "            tokenized = word_tokenize(line)\n",
    "\n",
    "\n",
    "            add_line = True\n",
    "            line_total = 0\n",
    "            line_unks = 0\n",
    "\n",
    "            unk_str = \"\"\n",
    "            for word in tokenized:\n",
    "                \n",
    "                total_words +=1\n",
    "                line_total +=1\n",
    "\n",
    "                if bool(re.search('[\\u0E00-\\u0E7F]+', word, flags=re.UNICODE)) and not ((word in vocab['white_listed']) or\\\n",
    "                                                            (word in vocab['black_listed'])):\n",
    "\n",
    "                        unk_str += '\"'+word+'\"'+\", \"\n",
    "                        if not percent_threshold:\n",
    "                            add_line = False\n",
    "                        disallowed_words.add(word)\n",
    "                        unknown_words +=1\n",
    "                        line_unks +=1\n",
    "\n",
    "            if percent_threshold:\n",
    "                if line_total>0:\n",
    "                    if (1-(line_unks/line_total))<percent_threshold:\n",
    "                        add_line = False\n",
    "            if add_line:\n",
    "                known_array.append(line)\n",
    "                unk_array.append(\"...\")\n",
    "            else:\n",
    "                known_array.append(\"...\")\n",
    "                unk_array.append(line)\n",
    "\n",
    "            if len(unk_str)>0:\n",
    "                unk_str = unk_str[0:len(unk_str)-2]\n",
    "\n",
    "            unknowns.append(unk_str)\n",
    "\n",
    "        if print_word_lvl and total_words>0:\n",
    "            print(\"word-level % known = \"+str((1-(unknown_words/total_words))*100))\n",
    "        if return_percent and total_words>0:\n",
    "            return (1-(unknown_words/total_words))*100\n",
    "        return_pd = pd.DataFrame(list(zip(known_array,unk_array,unknowns)))\n",
    "        return_pd.columns = [\"knowns\",\"unknowns\",\"unk_words\"]\n",
    "\n",
    "        \n",
    "\n",
    "        with open(path+'unknown_thai_list.txt',\"w\") as outfile:\n",
    "            outfile.write(str(list(disallowed_words)))\n",
    "\n",
    "        return return_pd\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "826dae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223\n",
      "2532\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read from existing .json formats\n",
    "uncovered, \n",
    "2223\n",
    "2532\n",
    "\"\"\"\n",
    "with open(path+source_file, \"r\") as path_in:\n",
    "    vocab = json.loads(path_in.read())\n",
    "vocab['white_listed'] = set(vocab['white_listed'])\n",
    "vocab['black_listed'] = set(vocab['black_listed'])\n",
    "print(len(vocab['white_listed'])) \n",
    "\n",
    "#get 4k freq word info:\n",
    "with open(path+'th_freq.csv','r') as infile:\n",
    "    freq_df = pd.read_csv(infile)\n",
    "uncovered = []\n",
    "for word in freq_df.word:\n",
    "    if word not in vocab['white_listed']:\n",
    "        uncovered.append(word)\n",
    "print(len(uncovered))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "004a939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking BBC Thai\n",
      "Checking VoiceTV\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "titles = []\n",
    "\n",
    "##BBC\n",
    "print(\"Checking BBC Thai\")\n",
    "parser = 'html.parser'  # or 'lxml' (preferred) or 'html5lib', if installed\n",
    "request=urllib.request.Request('https://www.bbc.com/thai/topics/cjgn73g98rqt',None,headers)\n",
    "resp = urllib.request.urlopen(request)\n",
    "soup = bs4.BeautifulSoup(resp, parser, from_encoding=resp.info().get_param('charset'))\n",
    "\n",
    "\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if 'https://www.bbc.com/thai/thailand' in str(link['href']):\n",
    "        pages.append(str(link['href']))\n",
    "        request=urllib.request.Request(str(link['href']),None,headers) #The assembled request\n",
    "\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "        if bool(re.search(\"(?<=ยอดนิยม หน้าแรก ประเทศไทย ต่างประเทศ วิทยาศาสตร์ สุขภาพ โควิด-19 วิดีโอ ยอดนิยม).{30}\",contents)):\n",
    "            titles.append(re.findall(\"(?<=ยอดนิยม หน้าแรก ประเทศไทย ต่างประเทศ วิทยาศาสตร์ สุขภาพ โควิด-19 วิดีโอ ยอดนิยม).{30}\",contents)[0].strip())\n",
    "\n",
    "    elif '/thai/thailand' in str(link['href']):\n",
    "        pages.append('https://www.bbc.com'+str(link['href']))\n",
    "\n",
    "##VoiceTV\n",
    "print(\"Checking VoiceTV\")\n",
    "parser = 'html.parser'  # or 'lxml' (preferred) or 'html5lib', if installed\n",
    "request=urllib.request.Request('https://www.voicetv.co.th/topic/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B9%80%E0%B8%A1%E0%B8%B7%E0%B8%AD%E0%B8%87',None,headers)\n",
    "resp = urllib.request.urlopen(request)\n",
    "soup = bs4.BeautifulSoup(resp, parser, from_encoding=resp.info().get_param('charset'))\n",
    "\n",
    " \n",
    "for link in soup.find_all('a', href=True):\n",
    "    str_page = 'https://www.voicetv.co.th'+str(link['href'])\n",
    "    if '/read/' in str(link['href']) and str_page not in pages:\n",
    "        pages.append(str_page)\n",
    "        request=urllib.request.Request(str_page,None,headers) #The assembled request\n",
    "\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "        titles.append(re.findall(\"(?<=  :).{30}\",contents)[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "411c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load prev corpus and add\n",
    "known_corpus = set()\n",
    "with open(path+\"all_known_thai_lines.txt\",\"r\",encoding='utf-8') as infile:\n",
    "    for line in infile.read().split('\\n'):\n",
    "        known_corpus.add(line)\n",
    "len(known_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb6ee0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent all known= 0.17898832684824903\n"
     ]
    }
   ],
   "source": [
    "#Find % of all sentences of news\n",
    "knowns = []\n",
    "all_lines = 0\n",
    "\n",
    "known_percents = []\n",
    "\n",
    "for webpage in pages:\n",
    "    \n",
    "    test_df = filter_text(webpage)\n",
    "    all_lines += len(list(test_df.knowns))\n",
    "    \n",
    "    known_percents.append(filter_text(webpage,return_percent=True))\n",
    "    \n",
    "    for item in list(test_df.knowns[test_df.knowns != '...']):\n",
    "        knowns.append(item)\n",
    "percent = len(knowns)/float(all_lines)\n",
    "print(\"percent all known= \"+str(percent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1fa348ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ทั้งนี้ต้องเรียนว่าเป็นการพิจารณากฎหมายคนละฉบับกัน ',\n",
       " 'ทำให้เห็นการเปลี่ยนแปลงที่ท่านต้องการให้เกิดขึ้น ',\n",
       " \"Last update Nov 30, 2022 12:58 )   ‘ประยุทธ์'\\u200b \",\n",
       " 'จึงจะได้รับการส่งเสริมและเติบโตทางการเมือง ',\n",
       " 'หวังว่าครั้งหน้าหากตนนำเสนอประเด็นอะไรอีก ',\n",
       " 'มีความกังวลก็เป็นคนรับผิดชอบเรื่องนี้ ',\n",
       " 'ยังรับหลักการเรื่องเหล่านี้ไม่ได้ ',\n",
       " 'แม้จะอธิบายว่ายังเป็นรัฐเดี่ยว ',\n",
       " 'วันที่ 30 พ.ย. 2565 ที่รัฐสภา ',\n",
       " 'ผมไม่ได้โดนตัดสิทธิความเป็นคน ',\n",
       " 'ปัญหาที่จะให้บ้านเมืองดีขึ้น ',\n",
       " 'ตนอยากเห็นประเทศเป็นรัฐเดียว ',\n",
       " 'มีความรับผิดชอบต่อบ้านเมือง ',\n",
       " 'จะไม่มีคำถามลักษณะนี้แล้ว ',\n",
       " 'อาจจะมีความสุขมากกว่านี้ ',\n",
       " 'ไม่รู้จะชัดอย่างไรแล้ว ',\n",
       " 'และไม่ได้ตื่นเต้นอะไร ',\n",
       " 'แต่ในข้อเสนอที่เสนอมา ',\n",
       " 'ประชาชนมากน้อยแค่ไหน ',\n",
       " 'ชี้หลักฐานไม่เพียงพอ ',\n",
       " 'ไม่อยากเป็นรัฐอิสระ ',\n",
       " 'ไม่มีประสบการณ์ ',\n",
       " 'ขั้นรับหลักการ ',\n",
       " 'Nov 30, 2022 ( ',\n",
       " 'กล่าวสั้นๆว่า\\u200b ',\n",
       " 'ไม่มีพรรค ',\n",
       " 'ไม่มีพวก ']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(list(set(knowns)),key=len,reverse=True)\n",
    "sorted(list(set(knowns).difference(known_corpus)),key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac029f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually remove from white\n",
    "remove_from_white = []\n",
    "\n",
    "for word in remove_from_white:\n",
    "    if word in vocab['white_listed']:\n",
    "        vocab['white_listed'].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1ee450fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1321"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in list(set(knowns)):\n",
    "    known_corpus.add(item)\n",
    "\n",
    "with open(path+\"all_known_thai_lines.txt\",\"w\",encoding='utf-8') as outfile:\n",
    "    for line in list(set(known_corpus)):\n",
    "        outfile.write(line+'\\n')\n",
    "len(known_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2d6948c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "websites = set()\n",
    "\n",
    "with open(path+'viewed_websites_th.txt',\"r\") as infile:\n",
    "    for line in infile.read().split('\\n'):\n",
    "        websites.add(line)\n",
    "print(len(websites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2a643828",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  88.40262582056893,\n",
       "  \"'อนุสรณ์' ชี้ ครม.ใหม่ ตอกย้ำ\",\n",
       "  'https://www.voicetv.co.th/read/-dpe9j2EE'),\n",
       " (3,\n",
       "  87.8727634194831,\n",
       "  \"อสส. ชี้ขาดไม่ฟ้อง 'ธนาธร' คด\",\n",
       "  'https://www.voicetv.co.th/read/TYnIOemq1'),\n",
       " (1,\n",
       "  86.14591009579956,\n",
       "  '‘ประยุทธ์’รับเป็นภูมิแพ้ ยังก',\n",
       "  'https://www.voicetv.co.th/read/I91kTy593'),\n",
       " (0,\n",
       "  85.59592096876992,\n",
       "  '‘ปิยบุตร’ ฟาด ส.ว.ย้ำยังมีสิท',\n",
       "  'https://www.bbc.com/thai/thailand-63662204'),\n",
       " (5,\n",
       "  81.50087260034904,\n",
       "  '‘วิษณุ’แย้มประตูยุบสภาเปิดอยู',\n",
       "  'https://www.voicetv.co.th/read/bn95YMr0a'),\n",
       " (7,\n",
       "  80.81123244929798,\n",
       "  'จับตา ‘ราษฎรแรลลี่’ จาก ‘วังล',\n",
       "  'https://www.voicetv.co.th/read/rI-9LjhEh'),\n",
       " (4,\n",
       "  77.67272727272727,\n",
       "  '‘ประยุทธ์’ อวยพรปีใหม่สื่อทำเ',\n",
       "  'https://www.voicetv.co.th/read/3TMgEJe-4')]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_titles = list(zip(range(0,len(known_percents)),known_percents,titles,pages))\n",
    "# (sorted(list(zip(range(0,len(known_percents)),known_percents)),key = lambda x: x[1],reverse=True))\n",
    "page_titles = sorted(page_titles,key = lambda x: x[1],reverse=True)\n",
    "page_titles = [item for item in page_titles if not (item[3] in websites)]\n",
    "page_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e2e7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = pages[2]\n",
    "if webpage in websites:\n",
    "    print(\"already scanned! choose another!\")\n",
    "websites.add(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f737a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(path+'viewed_websites_th.txt',\"w\") as outfile:\n",
    "    for line in websites:\n",
    "        outfile.write(line+'\\n')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "141ae514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word-level % known = 88.40262582056893\n"
     ]
    }
   ],
   "source": [
    "#display() #percent_threshold=0.95\n",
    "art=filter_text(webpage,print_word_lvl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8bce1137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "with open(path+'unknown_thai_list.txt',\"r\") as input_file:\n",
    "    new_words = input_file.read()\n",
    "    new_words = re.sub(\"[\\n\\'\\[\\]]\",\"\",new_words)\n",
    "    new_words = new_words.split(',')\n",
    "    new_words = [line.strip() for line in new_words] #update regex\n",
    "#new_words\n",
    "print(len(new_words))\n",
    "#known_manual = get_known(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "efd86a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitosheet\n",
    "unk_df = pd.DataFrame(new_words)\n",
    "unk_df.columns = ['word']\n",
    "unk_df['status'] = pd.Series(['' for word in new_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3663bb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f295adec7254feb8d5b5890ec5ed9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MitoWidget(analysis_data_json='{\"analysisName\": \"id-cvpyexlwel\", \"analysisToReplay\": null, \"code\": [], \"stepSu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mitosheet.sheet(unk_df, analysis_to_replay=\"id-cvpyexlwel\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442e3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "60d5d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ints = [9, 14, 16, 21, 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "77eb121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in add_ints:\n",
    "    # Set a cell value in status\n",
    "    unk_df.at[i, 'status'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "71c577e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "for i in range(0,len(unk_df)):\n",
    "    try:\n",
    "        translations.append(ts.google(unk_df.word.iloc[i]))\n",
    "    except:\n",
    "        translations.append('')\n",
    "unk_df['translations']=translations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fe5bce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31047e1de7241e5a5481fda6098394d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MitoWidget(analysis_data_json='{\"analysisName\": \"id-dtrcxszery\", \"analysisToReplay\": null, \"code\": [], \"stepSu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mitosheet.sheet(unk_df, analysis_to_replay=\"id-dtrcxszery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a703b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mitosheet import *; register_analysis(\"id-dtrcxszery\");\n",
    "    \n",
    "# Set a cell value in status\n",
    "unk_df.at[2, 'status'] = \"k\"\n",
    "\n",
    "# Set a cell value in status\n",
    "unk_df.at[4, 'status'] = \"k\"\n",
    "\n",
    "# Set a cell value in status\n",
    "unk_df.at[8, 'status'] = \"k\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "455c3cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "add_words = list(unk_df.word[unk_df['status']=='k'])\n",
    "print(len(add_words))\n",
    "for word in add_words:\n",
    "    vocab['white_listed'].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "02a15572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231\n"
     ]
    }
   ],
   "source": [
    "#write to .json formats\n",
    "df = vocab\n",
    "df['white_listed'] = list(df['white_listed'])\n",
    "df['black_listed'] = list(df['black_listed'])\n",
    "with open(path+source_file, \"w\") as outfile:\n",
    "    json.dump(df,outfile)\n",
    "print(len(df['white_listed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c7f67a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2231\n"
     ]
    }
   ],
   "source": [
    "#read from existing .json formats\n",
    "with open(path+source_file, \"r\") as path_in:\n",
    "    vocab = json.loads(path_in.read())\n",
    "vocab['white_listed'] = set(vocab['white_listed'])\n",
    "vocab['black_listed'] = set(vocab['black_listed'])\n",
    "print(len(vocab['white_listed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4f09c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.voicetv.co.th/read/-dpe9j2EE\n",
      "word-level % known = 90.59080962800876\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div id=4aac0098-f57b-4b76-bfb4-d74ebf3b7be2 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('4aac0098-f57b-4b76-bfb4-d74ebf3b7be2').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowns</th>\n",
       "      <th>unknowns</th>\n",
       "      <th>unk_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS LIVE POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS ABOUT FAQ CONTACT TERM OF USE SCHEDULE ไม่พบผลการค้นหา</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...</td>\n",
       "      <td>คุณกำลังอ่าน  : ‘ประยุทธ์’รับเป็นภูมิแพ้</td>\n",
       "      <td>\"ภูมิแพ้\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...</td>\n",
       "      <td>ยังกั๊กอนาคตการเมือง เลี่ยงตอบสูตรหาร 100 Share Tweet Share การเมือง ‘ประยุทธ์’รับเป็นภูมิแพ้</td>\n",
       "      <td>\"กั๊ก\", \"เลี่ยง\", \"สูตร\", \"หาร\", \"ภูมิแพ้\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...</td>\n",
       "      <td>ยังกั๊กอนาคตการเมือง เลี่ยงตอบสูตรหาร 100 Nov 30, 2022 (</td>\n",
       "      <td>\"กั๊ก\", \"เลี่ยง\", \"สูตร\", \"หาร\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last update Nov 30, 2022 12:58 )   ‘ประยุทธ์'​</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>กล่าวสั้นๆว่า​</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ไม่รู้เรื่องอะ​</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>...</td>\n",
       "      <td>เราไม่ค่อยรู้เรื่องเท่าไร ผู้สื่อข่าวรายงานว่า​ ตั้งแต่ภารกิจของนายกรัฐมนตรีในช่วงเช้ามอบรางวัล​รัฐบาลดิจิทัล​ประจำปี​ 2022 และภารกิจในช่วงบ่ายในการลงพื้นที่จังหวัดเชียงราย</td>\n",
       "      <td>\"ภารกิจ\", \"มอบ\", \"รางวัล\", \"ภารกิจ\", \"บ่าย\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>...</td>\n",
       "      <td>นายกรัฐมนตรีมีอาการคัดจมูกและสูดน้ำมูกตลอดทั้งวัน พร้อมออกตัวว่าเป็นภูมิแพ้</td>\n",
       "      <td>\"คัดจมูก\", \"สูด\", \"น้ำมูก\", \"ออกตัว\", \"ภูมิแพ้\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>...</td>\n",
       "      <td>ไม่ได้เป็นโควิด-19 ล่าสุดหลังการเดินทางลงพื้นที่จังหวัดเชียงราย ได้มีทีมแพทย์มาตรวจหาเชื้อโควิด​ -​19 ให้กับนายกรัฐมนตรี​ Topic การเมือง , ศาลรัฐธรรมนูญ People ประยุทธ์ จันทร์โอชา Author กองบรรณาธิการวอยซ์ออนไลน์ 51047 Article 1192 Video 10 Blog MOST VIEWED READ WATCH ABOUT FAQ CONTACT TERM OF USE SCHEDULE</td>\n",
       "      <td>\"ล่าสุด\", \"ตรวจหา\", \"เชื้อ\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                 knowns  \\\n",
       "0      POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS LIVE POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS ABOUT FAQ CONTACT TERM OF USE SCHEDULE ไม่พบผลการค้นหา    \n",
       "1   ...                                                                                                                                                                                                                                                   \n",
       "2   ...                                                                                                                                                                                                                                                   \n",
       "3   ...                                                                                                                                                                                                                                                   \n",
       "4   Last update Nov 30, 2022 12:58 )   ‘ประยุทธ์'​                                                                                                                                                                                                        \n",
       "5   ...                                                                                                                                                                                                                                                   \n",
       "6   บอกตัวเองไม่ค่อยรู้เรื่องเท่าไร วันที่ 30 พ.ย. 2565 พล.อ.ประยุทธ์​ จันทร์โอชา​ นายกรัฐมนตรี และรัฐมนตรีว่าการกระทรวงกลาโหม​ ให้สัมภาษณ์ภายหลังจากการเดินทางกลับจากการลงพื้นที่​                                                                       \n",
       "7   ...                                                                                                                                                                                                                                                   \n",
       "8   ...                                                                                                                                                                                                                                                   \n",
       "9   ...                                                                                                                                                                                                                                                   \n",
       "10  ว่า “ก็เป็นไปตามศาลรัฐธรรมนูญเลยจ๊ะ”                                                                                                                                                                                                                  \n",
       "11  ...                                                                                                                                                                                                                                                   \n",
       "12  กล่าวสั้นๆว่า​                                                                                                                                                                                                                                        \n",
       "13  ไม่รู้เรื่องอะ​                                                                                                                                                                                                                                       \n",
       "14  ...                                                                                                                                                                                                                                                   \n",
       "15  ...                                                                                                                                                                                                                                                   \n",
       "16  ...                                                                                                                                                                                                                                                   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                     unknowns  \\\n",
       "0   ...                                                                                                                                                                                                                                                                                                                         \n",
       "1   คุณกำลังอ่าน  : ‘ประยุทธ์’รับเป็นภูมิแพ้                                                                                                                                                                                                                                                                                    \n",
       "2   ยังกั๊กอนาคตการเมือง เลี่ยงตอบสูตรหาร 100 Share Tweet Share การเมือง ‘ประยุทธ์’รับเป็นภูมิแพ้                                                                                                                                                                                                                               \n",
       "3   ยังกั๊กอนาคตการเมือง เลี่ยงตอบสูตรหาร 100 Nov 30, 2022 (                                                                                                                                                                                                                                                                    \n",
       "4   ...                                                                                                                                                                                                                                                                                                                         \n",
       "5   ยังกั๊กอนาคตทางการเมือง​ เลี่ยงตอบสูตรหาร 100 จะ​มีผลต่อการตัดสินใจหรือไม่                                                                                                                                                                                                                                                  \n",
       "6   ...                                                                                                                                                                                                                                                                                                                         \n",
       "7   จ.เชียงราย​                                                                                                                                                                                                                                                                                                                 \n",
       "8   ถึงกรณีที่ศาลรัฐธรรมนูญมีคำวินิจฉัยให้ร่างพระราชบัญญัติประกอบรัฐธรรมนูญ (พ.ร.ป.) ว่าด้วยการเลือกตั้ง ส.ส. ไม่ขัดต่อรัฐธรรมนูญ โดยเป็นไปตามที่สภาขอแก้ไข                                                                                                                                                                     \n",
       "9   โดยใช้สูตรคำนวณ​ ส.ส.บัญชีรายชื่อแบบหาร 100 จะมีผลจะมีผลต่อการตัดสินใจทางการเมืองหรือไม่                                                                                                                                                                                                                                    \n",
       "10  ...                                                                                                                                                                                                                                                                                                                         \n",
       "11  เมื่อย้ำถามว่า สูตรหาร 100 จะมีผลอะไรหรือไม่​ พล.อ.ประยุทธ์                                                                                                                                                                                                                                                                 \n",
       "12  ...                                                                                                                                                                                                                                                                                                                         \n",
       "13  ...                                                                                                                                                                                                                                                                                                                         \n",
       "14  เราไม่ค่อยรู้เรื่องเท่าไร ผู้สื่อข่าวรายงานว่า​ ตั้งแต่ภารกิจของนายกรัฐมนตรีในช่วงเช้ามอบรางวัล​รัฐบาลดิจิทัล​ประจำปี​ 2022 และภารกิจในช่วงบ่ายในการลงพื้นที่จังหวัดเชียงราย                                                                                                                                                \n",
       "15  นายกรัฐมนตรีมีอาการคัดจมูกและสูดน้ำมูกตลอดทั้งวัน พร้อมออกตัวว่าเป็นภูมิแพ้                                                                                                                                                                                                                                                 \n",
       "16  ไม่ได้เป็นโควิด-19 ล่าสุดหลังการเดินทางลงพื้นที่จังหวัดเชียงราย ได้มีทีมแพทย์มาตรวจหาเชื้อโควิด​ -​19 ให้กับนายกรัฐมนตรี​ Topic การเมือง , ศาลรัฐธรรมนูญ People ประยุทธ์ จันทร์โอชา Author กองบรรณาธิการวอยซ์ออนไลน์ 51047 Article 1192 Video 10 Blog MOST VIEWED READ WATCH ABOUT FAQ CONTACT TERM OF USE SCHEDULE         \n",
       "\n",
       "                                                                         unk_words  \n",
       "0                                                                                   \n",
       "1   \"ภูมิแพ้\"                                                                       \n",
       "2   \"กั๊ก\", \"เลี่ยง\", \"สูตร\", \"หาร\", \"ภูมิแพ้\"                                      \n",
       "3   \"กั๊ก\", \"เลี่ยง\", \"สูตร\", \"หาร\"                                                 \n",
       "4                                                                                   \n",
       "5   \"กั๊ก\", \"เลี่ยง\", \"สูตร\", \"หาร\", \"มีผลต่อ\"                                      \n",
       "6                                                                                   \n",
       "7   \"จ.\"                                                                            \n",
       "8   \"คำวินิจฉัย\", \"พระราชบัญญัติประกอบรัฐธรรมนูญ\", \"(พ.\", \"ป.\", \"ขัดต่อ\", \"ตามที่\"  \n",
       "9   \"สูตร\", \"คำนวณ\", \"หาร\", \"มีผลต่อ\"                                               \n",
       "10                                                                                  \n",
       "11  \"สูตร\", \"หาร\", \"​ พ\", \"ล.\"                                                      \n",
       "12                                                                                  \n",
       "13                                                                                  \n",
       "14  \"ภารกิจ\", \"มอบ\", \"รางวัล\", \"ภารกิจ\", \"บ่าย\"                                     \n",
       "15  \"คัดจมูก\", \"สูด\", \"น้ำมูก\", \"ออกตัว\", \"ภูมิแพ้\"                                 \n",
       "16  \"ล่าสุด\", \"ตรวจหา\", \"เชื้อ\"                                                     "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(webpage)\n",
    "filter_text(webpage,print_word_lvl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bfa91",
   "metadata": {},
   "source": [
    "##END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "db36cdb8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily catch in word count:\n",
      "['เชิญ', 'ยิ้ม', 'ยินดี', 'รอย', 'เอกสาร', 'สนิท', 'กระดาษ', 'คอ', 'โรงพยาบาล', 'หิน', 'จด', 'ปืน', 'โต๊ะ', 'เสื้อผ้า', 'เลือด', 'สิทธิ์', 'นักเขียน', 'สนุกสนาน', 'หัวเราะ', 'หู', 'ยิง', 'สวยงาม', 'ล่า', 'แขก', 'ดอกไม้', 'ที่นั่ง', 'เสือ', 'ปกป้อง', 'รับประทาน', 'ไอ', 'สนุก', 'ลูกชาย', 'สหรัฐ', 'นิ้ว', 'ไอ้', 'รถไฟ', 'เล็กน้อย', 'โปรด', 'คะแนน', 'กรุณา', 'โรงแรม', 'จดหมาย', 'ขับ', 'ดื่ม', 'หอม', 'ระมัดระวัง', 'ฤดู', 'ฟัน', 'เท้า', 'หล่อน', 'วางแผน', 'ลับ', 'ลอย', 'ยกเว้น', 'ลูกค้า', 'ริม', 'ม้า', 'คอมพิวเตอร์']\n"
     ]
    }
   ],
   "source": [
    "#Upload from download\n",
    "with open(path+'known_thai_list.txt',\"r\") as input_file:\n",
    "    new_words = input_file.read().split(',')\n",
    "    print(\"daily catch in word count:\")\n",
    "    print(new_words)\n",
    "for line in new_words:   \n",
    "    vocab['white_listed'].add(line.replace(\"'\",\"\").strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0141a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Nong\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wyw_text = 'สวัสดีครับน้อง'\n",
    "print(ts.google(wyw_text))\n",
    "#print(ts._google.language_map)\n",
    "#print(ts.google(wyw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "67b1cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today's catch % of corpus:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.200344766395417%'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get after when adding in new words\n",
    "print(\"today's catch % of corpus:\")\n",
    "str(100*(percent-prev_percent))+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output newly knowns\n",
    "with open(path+\"new_known_thai_lines.txt\",\"w\") as outfile:\n",
    "    for line in list(set(knowns).difference(prev_knowns)):\n",
    "        outfile.write(line+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a9fb3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check. Current vocab size:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sanity check. Current vocab size:\")\n",
    "len(vocab['white_listed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "564b37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "to do:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9799280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##INPUT-OUTPUT\n",
    "#vocab list:\n",
    "with open(\"/Users/elyebliss/Desktop/Vocabulary/vocab_dfs/thai_whitelisted.csv\",\"r\") as infile:\n",
    "    whitelisted_lemmas = infile.read()\n",
    "\n",
    "\n",
    "##VARIABLES\n",
    "vocab_all = set()\n",
    "\n",
    "\n",
    "for line in whitelisted_lemmas.split('\\n'):\n",
    "    if len(line) > 0:\n",
    "        \n",
    "        vocab = line.strip()\n",
    "        vocab_all.add(vocab)\n",
    "        \n",
    "len(whitelisted_lemmas.split('\\n'))            \n",
    "#pp.pprint(vocab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e37bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "vocab['white_listed'] = list(vocab_all)\n",
    "vocab['black_listed'] = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
