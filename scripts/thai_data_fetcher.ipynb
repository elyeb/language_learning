{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aba0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Contents:\n",
    "-data intialization from csv file of words &\n",
    " build data structure to house info moving forward\n",
    "-write to .json formats\n",
    "-read from existing .json formats\n",
    "-get list of words to find\n",
    "-scrape BBC\n",
    "-scrape voiceTV\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdc6804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using state Washington server backend.\n"
     ]
    }
   ],
   "source": [
    "import bs4, requests, sys, codecs, urllib.request, re\n",
    "from bs4 import SoupStrainer\n",
    "from bs4.element import Comment\n",
    "import random\n",
    "#import pythainlp\n",
    "from pythainlp.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pprint\n",
    "import translators as ts\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n",
    "path = \"/Users/elyebliss/Desktop/Vocabulary/language_learning/vocab_dfs/\"\n",
    "source_file = \"thai.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce69b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##METHODS\n",
    "\n",
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = bs4.BeautifulSoup(body, 'html.parser')\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 6.3; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'\n",
    "headers={'User-Agent':user_agent,}\n",
    "parser = 'html.parser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63afba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_known(unknown_list):\n",
    "    \n",
    "    count_got = 0\n",
    "    known_list = []\n",
    "    for word in unknown_list:\n",
    "        decision = str(input(word+\"\\nKnown =k\"))\n",
    "        if decision =='k':\n",
    "            known_list.append(word)\n",
    "            count_got +=1\n",
    "            print(\"got \"+str(count_got))\n",
    "        elif decision=='q':\n",
    "            break\n",
    "        try:\n",
    "            print(ts.google(word))\n",
    "        except:\n",
    "            print('cant find')\n",
    "    return known_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117b26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(webpage,start=None,stop=None,\\\n",
    "                print_word_lvl=False,percent_threshold=None,\\\n",
    "               return_percent=False):\n",
    "\n",
    "\n",
    "    try:\n",
    "        request=urllib.request.Request(webpage,None,headers) #The assembled request\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "\n",
    "        known_array = []\n",
    "        unk_array = []\n",
    "        contents_array = sent_tokenize(contents)\n",
    "\n",
    "        if (start is not None) and (stop is not None):\n",
    "            contents_array=contents_array[max(start,0):min(stop,len(contents_array))]\n",
    "\n",
    "        disallowed_words = set()\n",
    "\n",
    "        total_words = 0\n",
    "        unknown_words = 0\n",
    "        \n",
    "        lines = []\n",
    "        unknowns = []\n",
    "        for line in contents_array:\n",
    "\n",
    "\n",
    "            tokenized = word_tokenize(line)\n",
    "\n",
    "\n",
    "            add_line = True\n",
    "            line_total = 0\n",
    "            line_unks = 0\n",
    "\n",
    "            unk_str = \"\"\n",
    "            for word in tokenized:\n",
    "                \n",
    "                total_words +=1\n",
    "                line_total +=1\n",
    "\n",
    "                if bool(re.search('[\\u0E00-\\u0E7F]+', word, flags=re.UNICODE)) and not ((word in vocab['white_listed']) or\\\n",
    "                                                            (word in vocab['black_listed'])):\n",
    "\n",
    "                        unk_str += '\"'+word+'\"'+\", \"\n",
    "                        if not percent_threshold:\n",
    "                            add_line = False\n",
    "                        disallowed_words.add(word)\n",
    "                        unknown_words +=1\n",
    "                        line_unks +=1\n",
    "\n",
    "            if percent_threshold:\n",
    "                if line_total>0:\n",
    "                    if (1-(line_unks/line_total))<percent_threshold:\n",
    "                        add_line = False\n",
    "            if add_line:\n",
    "                known_array.append(line)\n",
    "                unk_array.append(\"...\")\n",
    "            else:\n",
    "                known_array.append(\"...\")\n",
    "                unk_array.append(line)\n",
    "\n",
    "            if len(unk_str)>0:\n",
    "                unk_str = unk_str[0:len(unk_str)-2]\n",
    "\n",
    "            unknowns.append(unk_str)\n",
    "\n",
    "        if print_word_lvl and total_words>0:\n",
    "            print(\"word-level % known = \"+str((1-(unknown_words/total_words))*100))\n",
    "        if return_percent and total_words>0:\n",
    "            return (1-(unknown_words/total_words))*100\n",
    "        return_pd = pd.DataFrame(list(zip(known_array,unk_array,unknowns)))\n",
    "        return_pd.columns = [\"knowns\",\"unknowns\",\"unk_words\"]\n",
    "\n",
    "        \n",
    "\n",
    "        with open(path+'unknown_thai_list.txt',\"w\") as outfile:\n",
    "            outfile.write(str(list(disallowed_words)))\n",
    "\n",
    "        return return_pd\n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826dae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2155\n",
      "2544\n"
     ]
    }
   ],
   "source": [
    "\"\"\"read from existing .json formats\n",
    "uncovered, \n",
    "2155\n",
    "2544\n",
    "\"\"\"\n",
    "with open(path+source_file, \"r\") as path_in:\n",
    "    vocab = json.loads(path_in.read())\n",
    "vocab['white_listed'] = set(vocab['white_listed'])\n",
    "vocab['black_listed'] = set(vocab['black_listed'])\n",
    "print(len(vocab['white_listed'])) \n",
    "\n",
    "#get 4k freq word info:\n",
    "with open(path+'th_freq.csv','r') as infile:\n",
    "    freq_df = pd.read_csv(infile)\n",
    "uncovered = []\n",
    "for word in freq_df.word:\n",
    "    if word not in vocab['white_listed']:\n",
    "        uncovered.append(word)\n",
    "print(len(uncovered))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004a939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking BBC Thai\n",
      "Checking VoiceTV\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "titles = []\n",
    "\n",
    "##BBC\n",
    "print(\"Checking BBC Thai\")\n",
    "parser = 'html.parser'  # or 'lxml' (preferred) or 'html5lib', if installed\n",
    "request=urllib.request.Request('https://www.bbc.com/thai/topics/cjgn73g98rqt',None,headers)\n",
    "resp = urllib.request.urlopen(request)\n",
    "soup = bs4.BeautifulSoup(resp, parser, from_encoding=resp.info().get_param('charset'))\n",
    "\n",
    "\n",
    "for link in soup.find_all('a', href=True):\n",
    "    if 'https://www.bbc.com/thai/thailand' in str(link['href']):\n",
    "        pages.append(str(link['href']))\n",
    "        request=urllib.request.Request(str(link['href']),None,headers) #The assembled request\n",
    "\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "        if bool(re.search(\"(?<=ยอดนิยม หน้าแรก ประเทศไทย ต่างประเทศ วิทยาศาสตร์ สุขภาพ โควิด-19 วิดีโอ ยอดนิยม).{30}\",contents)):\n",
    "            titles.append(re.findall(\"(?<=ยอดนิยม หน้าแรก ประเทศไทย ต่างประเทศ วิทยาศาสตร์ สุขภาพ โควิด-19 วิดีโอ ยอดนิยม).{30}\",contents)[0].strip())\n",
    "\n",
    "    elif '/thai/thailand' in str(link['href']):\n",
    "        pages.append('https://www.bbc.com'+str(link['href']))\n",
    "\n",
    "##VoiceTV\n",
    "print(\"Checking VoiceTV\")\n",
    "parser = 'html.parser'  # or 'lxml' (preferred) or 'html5lib', if installed\n",
    "request=urllib.request.Request('https://www.voicetv.co.th/topic/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B9%80%E0%B8%A1%E0%B8%B7%E0%B8%AD%E0%B8%87',None,headers)\n",
    "resp = urllib.request.urlopen(request)\n",
    "soup = bs4.BeautifulSoup(resp, parser, from_encoding=resp.info().get_param('charset'))\n",
    "\n",
    " \n",
    "for link in soup.find_all('a', href=True):\n",
    "    str_page = 'https://www.voicetv.co.th'+str(link['href'])\n",
    "    if '/read/' in str(link['href']) and str_page not in pages:\n",
    "        pages.append(str_page)\n",
    "        request=urllib.request.Request(str_page,None,headers) #The assembled request\n",
    "\n",
    "        response = urllib.request.urlopen(request)\n",
    "        data = response.read()\n",
    "        contents = text_from_html(data)\n",
    "        titles.append(re.findall(\"(?<=  :).{30}\",contents)[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load prev corpus and add\n",
    "known_corpus = set()\n",
    "with open(path+\"all_known_thai_lines.txt\",\"r\",encoding='utf-8') as infile:\n",
    "    for line in infile.read().split('\\n'):\n",
    "        known_corpus.add(line)\n",
    "len(known_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6ee0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent all known= 0.14193548387096774\n"
     ]
    }
   ],
   "source": [
    "#Find % of all sentences of news\n",
    "knowns = []\n",
    "all_lines = 0\n",
    "\n",
    "known_percents = []\n",
    "\n",
    "for webpage in pages:\n",
    "    \n",
    "    test_df = filter_text(webpage)\n",
    "    all_lines += len(list(test_df.knowns))\n",
    "    \n",
    "    known_percents.append(filter_text(webpage,return_percent=True))\n",
    "    \n",
    "    for item in list(test_df.knowns[test_df.knowns != '...']):\n",
    "        knowns.append(item)\n",
    "percent = len(knowns)/float(all_lines)\n",
    "print(\"percent all known= \"+str(percent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa348ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ขณะที่รัฐสภานำกำลังตำรวจกว่า 30 นาย มาดูแลความเรียบร้อย ',\n",
       " \"Last update Nov 23, 2022 15:58 )   'ประยุทธ์' \",\n",
       " 'ตนได้ยินว่า วันนี้มีการเช็กชื่อ ส.ส. ',\n",
       " 'ไม่ได้ตั้งใจจะมามีเรื่องกับใคร ',\n",
       " 'เพราะไม่ได้อยู่ในเหตุการณ์ ',\n",
       " 'เชื่อว่าสภาจะเดินต่อลำบาก ',\n",
       " 'เนื่องจากก่อนหน้านี้นายกฯ ',\n",
       " 'ซึ่งไม่เคยเกิดขึ้นมาก่อน ',\n",
       " 'คืนอำนาจให้ประชาชน ด้าน ',\n",
       " 'เมื่อ 30 นาทีที่ผ่านมา ',\n",
       " 'เมื่อ 31 นาทีที่ผ่านมา ',\n",
       " 'รัฐสภาเป็นที่ของทุกคน ',\n",
       " 'ตนเองไม่อยากมีเรื่อง ',\n",
       " 'ไม่เดินทางกลับทันที ',\n",
       " 'ซึ่งอาจจะมาทำร้าย ',\n",
       " 'ทำให้มีคนไม่พอใจ ',\n",
       " 'มีฝ่ายนักสู้ ',\n",
       " 'มาถึงรัฐสภา ',\n",
       " 'ระดับหนึ่ง ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(list(set(knowns)),key=len,reverse=True)\n",
    "sorted(list(set(knowns).difference(known_corpus)),key=len,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee450fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1144"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in list(set(knowns)):\n",
    "    known_corpus.add(item)\n",
    "\n",
    "with open(path+\"all_known_thai_lines.txt\",\"w\",encoding='utf-8') as outfile:\n",
    "    for line in list(set(known_corpus)):\n",
    "        outfile.write(line+'\\n')\n",
    "len(known_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6948c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "websites = set()\n",
    "websites.add(webpage)\n",
    "with open(path+'viewed_websites_th.txt',\"r\") as infile:\n",
    "    for line in infile.read().split('\\n'):\n",
    "        websites.add(line)\n",
    "print(len(websites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a643828",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5,\n",
       "  90.61728395061728,\n",
       "  '‘วิษณุ’แย้มประตูยุบสภาเปิดอยู',\n",
       "  'https://www.voicetv.co.th/read/pGzNyn4So'),\n",
       " (0,\n",
       "  85.6958762886598,\n",
       "  '‘เพื่อไทย’บี้ยุบสภาฯ แฉเหตุสภ',\n",
       "  'https://www.bbc.com/thai/thailand-63662204'),\n",
       " (4,\n",
       "  82.22637979420018,\n",
       "  '‘ประยุทธ์’ อวยพรปีใหม่สื่อทำเ',\n",
       "  'https://www.voicetv.co.th/read/8UgIHSEp8'),\n",
       " (1,\n",
       "  81.785944551902,\n",
       "  \"‘โทนี่’ ทวีตแจงปมดราม่า 'แดงข\",\n",
       "  'https://www.bbc.com/thai/thailand-63566397'),\n",
       " (3,\n",
       "  81.62111215834119,\n",
       "  '‘ประยุทธ์’ยื้อตอบการเมืองชัดเ',\n",
       "  'https://www.voicetv.co.th/read/nl7gMupZI'),\n",
       " (2,\n",
       "  81.45580589254766,\n",
       "  \"หวิดวางมวย 'สันธนะ' เจอ 'ชูวิ\",\n",
       "  'https://www.voicetv.co.th/read/nayWOhdZu'),\n",
       " (6,\n",
       "  80.27923211169285,\n",
       "  \"รีวิว 'Collective': นักข่าวไม\",\n",
       "  'https://www.voicetv.co.th/read/bn95YMr0a')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_titles = list(zip(range(0,len(known_percents)),known_percents,titles,pages))\n",
    "# (sorted(list(zip(range(0,len(known_percents)),known_percents)),key = lambda x: x[1],reverse=True))\n",
    "page_titles = sorted(page_titles,key = lambda x: x[1],reverse=True)\n",
    "page_titles = [item for item in page_titles if not (item[3] in websites)]\n",
    "page_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e2e7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage = pages[5]\n",
    "if webpage in websites:\n",
    "    print(\"already scanned! choose another!\")\n",
    "websites.add(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f737a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(path+'viewed_websites_th.txt',\"w\") as outfile:\n",
    "    for line in websites:\n",
    "        outfile.write(line+'\\n')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "141ae514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word-level % known = 90.61728395061728\n"
     ]
    }
   ],
   "source": [
    "#display() #percent_threshold=0.95\n",
    "art=filter_text(webpage,print_word_lvl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bce1137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "with open(path+'unknown_thai_list.txt',\"r\") as input_file:\n",
    "    new_words = input_file.read()\n",
    "    new_words = re.sub(\"[\\n\\'\\[\\]]\",\"\",new_words)\n",
    "    new_words = new_words.split(',')\n",
    "    new_words = [line.strip() for line in new_words] #update regex\n",
    "#new_words\n",
    "print(len(new_words))\n",
    "#known_manual = get_known(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efd86a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitosheet\n",
    "unk_df = pd.DataFrame(new_words)\n",
    "unk_df.columns = ['word']\n",
    "unk_df['status'] = pd.Series(['' for word in new_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3663bb4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d199c752c34f60b8fadd3076756639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MitoWidget(analysis_data_json='{\"analysisName\": \"id-cmzasqzjif\", \"analysisToReplay\": null, \"code\": [], \"stepSu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mitosheet.sheet(unk_df, analysis_to_replay=\"id-cmzasqzjif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60d5d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ints = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77eb121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in add_ints:\n",
    "    # Set a cell value in status\n",
    "    unk_df.at[i, 'status'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71c577e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=d74175e4-bfa0-425d-976e-8a5357839b8c style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('d74175e4-bfa0-425d-976e-8a5357839b8c').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>status</th>\n",
       "      <th>translations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>เคลื่อน</td>\n",
       "      <td></td>\n",
       "      <td>move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>หันมา</td>\n",
       "      <td>k</td>\n",
       "      <td>Turn around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>บีทีเอส</td>\n",
       "      <td>k</td>\n",
       "      <td>BTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>นู่น</td>\n",
       "      <td></td>\n",
       "      <td>over there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ร่วมงาน</td>\n",
       "      <td></td>\n",
       "      <td>Join</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ซบ</td>\n",
       "      <td></td>\n",
       "      <td>nestle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>พรรคพลังประชารัฐ</td>\n",
       "      <td></td>\n",
       "      <td>Pracharat Power Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>รวมไปถึง</td>\n",
       "      <td></td>\n",
       "      <td>Include</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ลั่น</td>\n",
       "      <td></td>\n",
       "      <td>Disseminate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ทวงถาม</td>\n",
       "      <td></td>\n",
       "      <td>Demand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                word status           translations\n",
       "0   เคลื่อน                  move                 \n",
       "1   หันมา             k      Turn around          \n",
       "2   บีทีเอส           k      BTS                  \n",
       "3   นู่น                     over there           \n",
       "4   ร่วมงาน                  Join                 \n",
       "5   กวดขัน                   rigorous             \n",
       "6   พปช                      PEC                  \n",
       "7   ยื้อ                     Disperse             \n",
       "8   แหละ              k      So                   \n",
       "9   สุวรรณ                   Suwan                \n",
       "10  แยกทาง                   Separate             \n",
       "11  กองบรรณาธิการ     k      Editorial            \n",
       "12  สร้างชาติ         k      Create a nation      \n",
       "13  สัมปทาน                  concession           \n",
       "14  ประวิตร                  Prawit               \n",
       "15  จี้                      pendant              \n",
       "16  เมิน                     ignore               \n",
       "17  เกิดเหตุ                 Incident             \n",
       "18  จ.                       Province             \n",
       "19  นราธิวาส                 Narathiwat           \n",
       "20  ไร                       What                 \n",
       "21  วงษ์                     Wongwong             \n",
       "22  ซบ                       nestle               \n",
       "23  พรรคพลังประชารัฐ         Pracharat Power Party\n",
       "24  รวมไปถึง                 Include              \n",
       "25  ลั่น                     Disseminate          \n",
       "26  ทวงถาม                   Demand               "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations = []\n",
    "for i in range(0,len(unk_df)):\n",
    "    try:\n",
    "        translations.append(ts.google(unk_df.word.iloc[i]))\n",
    "    except:\n",
    "        translations.append('')\n",
    "unk_df['translations']=translations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe5bce81",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a0f283a1a748af90c643143e856029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MitoWidget(analysis_data_json='{\"analysisName\": \"id-lszfpmdpzf\", \"analysisToReplay\": null, \"code\": [], \"stepSu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mitosheet.sheet(unk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "455c3cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "add_words = list(unk_df.word[unk_df['status']=='k'])\n",
    "print(len(add_words))\n",
    "for word in add_words:\n",
    "    vocab['white_listed'].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27b8e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually remove from white\n",
    "remove_from_white = []\n",
    "\n",
    "for word in remove_from_white:\n",
    "    if word in vocab['white_listed']:\n",
    "        vocab['white_listed'].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2706f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually add to white\n",
    "add_to_white = []\n",
    "\n",
    "for word in add_to_white:\n",
    "    vocab['white_listed'].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6403a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(known_manual))\n",
    "for word in known_manual:\n",
    "    vocab['white_listed'].add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02a15572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2155\n"
     ]
    }
   ],
   "source": [
    "#write to .json formats\n",
    "df = vocab\n",
    "df['white_listed'] = list(df['white_listed'])\n",
    "df['black_listed'] = list(df['black_listed'])\n",
    "with open(path+source_file, \"w\") as outfile:\n",
    "    json.dump(df,outfile)\n",
    "print(len(df['white_listed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7f67a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2155\n"
     ]
    }
   ],
   "source": [
    "#read from existing .json formats\n",
    "with open(path+source_file, \"r\") as path_in:\n",
    "    vocab = json.loads(path_in.read())\n",
    "vocab['white_listed'] = set(vocab['white_listed'])\n",
    "vocab['black_listed'] = set(vocab['black_listed'])\n",
    "print(len(vocab['white_listed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f09c08d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.voicetv.co.th/read/pGzNyn4So\n",
      "word-level % known = 92.34567901234568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div id=b0c48bbb-b99f-47b0-a1cf-201b9e162b16 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('b0c48bbb-b99f-47b0-a1cf-201b9e162b16').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>knowns</th>\n",
       "      <th>unknowns</th>\n",
       "      <th>unk_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS LIVE POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS ABOUT FAQ CONTACT TERM OF USE SCHEDULE ไม่พบผลการค้นหา</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>...</td>\n",
       "      <td>คุณกำลังอ่าน  : ‘ประยุทธ์’ยื้อตอบการเมืองชัดเจน ให้สื่อรอปีหน้า เมินตอบแยกทาง 'ประวิตร' Share Tweet Share การเมือง ‘ประยุทธ์’ยื้อตอบการเมืองชัดเจน ให้สื่อรอปีหน้า เมินตอบแยกทาง 'ประวิตร' Nov 23, 2022 (</td>\n",
       "      <td>\"ยื้อ\", \"เมิน\", \"แยกทาง\", \"ประวิตร\", \"ยื้อ\", \"เมิน\", \"แยกทาง\", \"ประวิตร\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last update Nov 23, 2022 15:58 )   'ประยุทธ์'</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...</td>\n",
       "      <td>ลั่นชัดเจนการเมืองปีหน้า</td>\n",
       "      <td>\"ลั่น\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...</td>\n",
       "      <td>หลังสื่อฯจี้</td>\n",
       "      <td>\"จี้\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>...</td>\n",
       "      <td>วันที่ 23 พ.ย. 2565 พล.อ.ประยุทธ์ จันทร์โอชา นายกรัฐมนตรี และรัฐมนตรีว่าการกระทรวงกลาโหม ปฏิเสธตอบคำถามกรณีเกิดเหตุคาร์บอมบ์แฟลตตำรวจที่ จ.นราธิวาสว่าจะมีการกวดขันป้องกันอย่าไร</td>\n",
       "      <td>\"เกิดเหตุ\", \"จ.\", \"นราธิวาส\", \"กวดขัน\", \"ไร\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>รวมไปถึงกรณีการต่อขยายสัมปทานรถไฟฟ้าสายสีเขียวของบีทีเอส</td>\n",
       "      <td>\"รวมไปถึง\", \"สัมปทาน\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>...</td>\n",
       "      <td>และยังปฏิเสธการตอบคำถามถึงความชัดเจนทางการเมืองหลังมีกระแสข่าวแยกทางทางการเมืองกับ พล.อ.ประวิตร วงษ์สุวรรณ รองนายกรัฐมนตรี ในฐานะหัวหน้าพรรคพลังประชารัฐ (พปชร.) เพื่อร่วมงานกับพรรครวมไทยสร้างชาติ แต่เมื่อถามย้ำว่า การเมืองจะมีความชัดเจนเมื่อใด</td>\n",
       "      <td>\"แยกทาง\", \"ประวิตร\", \"วงษ์\", \"สุวรรณ\", \"พรรคพลังประชารัฐ\", \"พปช\", \"ร่วมงาน\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>เนื่องจากก่อนหน้านี้นายกฯ</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>...</td>\n",
       "      <td>เคยระบุไว้จะมีความชัดเจนหลังการประชุมเอเปคเสร็จ พล.อ.ประยุทธ์ ได้หันมามอง พร้อมระบุสั้นๆเพียงว่า \"หลังเอเปคก็ปีหน้านู่นแหละ​\" ก่อนที่รถจะเคลื่อนออกไป Topic การเมือง , พรรครวมไทยสร้างชาติ People ประยุทธ์ จันทร์โอชา Author กองบรรณาธิการวอยซ์ออนไลน์ 50942 Article 1192 Video 10 Blog MOST VIEWED READ WATCH ABOUT FAQ CONTACT TERM OF USE SCHEDULE</td>\n",
       "      <td>\"นู่น\", \"เคลื่อน\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                 knowns  \\\n",
       "0      POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS LIVE POLITICS ECONOMICS WORLD ENTERTAINMENT WELL-BEING LOCAL NEWS BLOG VOICE PLAZA TV PROGRAMS ABOUT FAQ CONTACT TERM OF USE SCHEDULE ไม่พบผลการค้นหา    \n",
       "1   ...                                                                                                                                                                                                                                                   \n",
       "2   Last update Nov 23, 2022 15:58 )   'ประยุทธ์'                                                                                                                                                                                                         \n",
       "3   ...                                                                                                                                                                                                                                                   \n",
       "4   ...                                                                                                                                                                                                                                                   \n",
       "5   ...                                                                                                                                                                                                                                                   \n",
       "6   ...                                                                                                                                                                                                                                                   \n",
       "7   ...                                                                                                                                                                                                                                                   \n",
       "8   ...                                                                                                                                                                                                                                                   \n",
       "9   ...                                                                                                                                                                                                                                                   \n",
       "10  เนื่องจากก่อนหน้านี้นายกฯ                                                                                                                                                                                                                             \n",
       "11  ...                                                                                                                                                                                                                                                   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                       unknowns  \\\n",
       "0   ...                                                                                                                                                                                                                                                                                                                                                           \n",
       "1   คุณกำลังอ่าน  : ‘ประยุทธ์’ยื้อตอบการเมืองชัดเจน ให้สื่อรอปีหน้า เมินตอบแยกทาง 'ประวิตร' Share Tweet Share การเมือง ‘ประยุทธ์’ยื้อตอบการเมืองชัดเจน ให้สื่อรอปีหน้า เมินตอบแยกทาง 'ประวิตร' Nov 23, 2022 (                                                                                                                                                     \n",
       "2   ...                                                                                                                                                                                                                                                                                                                                                           \n",
       "3   ลั่นชัดเจนการเมืองปีหน้า                                                                                                                                                                                                                                                                                                                                      \n",
       "4   หลังสื่อฯจี้                                                                                                                                                                                                                                                                                                                                                  \n",
       "5   ทวงถามหลังประชุมเอเปคจบ เมินตอบแยกทางถนนการเมือง 'ประวิตร​'                                                                                                                                                                                                                                                                                                   \n",
       "6   ซบรวมไทยสร้างชาติ                                                                                                                                                                                                                                                                                                                                             \n",
       "7   วันที่ 23 พ.ย. 2565 พล.อ.ประยุทธ์ จันทร์โอชา นายกรัฐมนตรี และรัฐมนตรีว่าการกระทรวงกลาโหม ปฏิเสธตอบคำถามกรณีเกิดเหตุคาร์บอมบ์แฟลตตำรวจที่ จ.นราธิวาสว่าจะมีการกวดขันป้องกันอย่าไร                                                                                                                                                                              \n",
       "8   รวมไปถึงกรณีการต่อขยายสัมปทานรถไฟฟ้าสายสีเขียวของบีทีเอส                                                                                                                                                                                                                                                                                                      \n",
       "9   และยังปฏิเสธการตอบคำถามถึงความชัดเจนทางการเมืองหลังมีกระแสข่าวแยกทางทางการเมืองกับ พล.อ.ประวิตร วงษ์สุวรรณ รองนายกรัฐมนตรี ในฐานะหัวหน้าพรรคพลังประชารัฐ (พปชร.) เพื่อร่วมงานกับพรรครวมไทยสร้างชาติ แต่เมื่อถามย้ำว่า การเมืองจะมีความชัดเจนเมื่อใด                                                                                                           \n",
       "10  ...                                                                                                                                                                                                                                                                                                                                                           \n",
       "11  เคยระบุไว้จะมีความชัดเจนหลังการประชุมเอเปคเสร็จ พล.อ.ประยุทธ์ ได้หันมามอง พร้อมระบุสั้นๆเพียงว่า \"หลังเอเปคก็ปีหน้านู่นแหละ​\" ก่อนที่รถจะเคลื่อนออกไป Topic การเมือง , พรรครวมไทยสร้างชาติ People ประยุทธ์ จันทร์โอชา Author กองบรรณาธิการวอยซ์ออนไลน์ 50942 Article 1192 Video 10 Blog MOST VIEWED READ WATCH ABOUT FAQ CONTACT TERM OF USE SCHEDULE         \n",
       "\n",
       "                                                                      unk_words  \n",
       "0                                                                                \n",
       "1   \"ยื้อ\", \"เมิน\", \"แยกทาง\", \"ประวิตร\", \"ยื้อ\", \"เมิน\", \"แยกทาง\", \"ประวิตร\"     \n",
       "2                                                                                \n",
       "3   \"ลั่น\"                                                                       \n",
       "4   \"จี้\"                                                                        \n",
       "5   \"ทวงถาม\", \"เมิน\", \"แยกทาง\", \"ประวิตร\"                                        \n",
       "6   \"ซบ\"                                                                         \n",
       "7   \"เกิดเหตุ\", \"จ.\", \"นราธิวาส\", \"กวดขัน\", \"ไร\"                                 \n",
       "8   \"รวมไปถึง\", \"สัมปทาน\"                                                        \n",
       "9   \"แยกทาง\", \"ประวิตร\", \"วงษ์\", \"สุวรรณ\", \"พรรคพลังประชารัฐ\", \"พปช\", \"ร่วมงาน\"  \n",
       "10                                                                               \n",
       "11  \"นู่น\", \"เคลื่อน\"                                                            "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(webpage)\n",
    "filter_text(webpage,print_word_lvl=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04bfa91",
   "metadata": {},
   "source": [
    "##END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "db36cdb8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily catch in word count:\n",
      "['เชิญ', 'ยิ้ม', 'ยินดี', 'รอย', 'เอกสาร', 'สนิท', 'กระดาษ', 'คอ', 'โรงพยาบาล', 'หิน', 'จด', 'ปืน', 'โต๊ะ', 'เสื้อผ้า', 'เลือด', 'สิทธิ์', 'นักเขียน', 'สนุกสนาน', 'หัวเราะ', 'หู', 'ยิง', 'สวยงาม', 'ล่า', 'แขก', 'ดอกไม้', 'ที่นั่ง', 'เสือ', 'ปกป้อง', 'รับประทาน', 'ไอ', 'สนุก', 'ลูกชาย', 'สหรัฐ', 'นิ้ว', 'ไอ้', 'รถไฟ', 'เล็กน้อย', 'โปรด', 'คะแนน', 'กรุณา', 'โรงแรม', 'จดหมาย', 'ขับ', 'ดื่ม', 'หอม', 'ระมัดระวัง', 'ฤดู', 'ฟัน', 'เท้า', 'หล่อน', 'วางแผน', 'ลับ', 'ลอย', 'ยกเว้น', 'ลูกค้า', 'ริม', 'ม้า', 'คอมพิวเตอร์']\n"
     ]
    }
   ],
   "source": [
    "#Upload from download\n",
    "with open(path+'known_thai_list.txt',\"r\") as input_file:\n",
    "    new_words = input_file.read().split(',')\n",
    "    print(\"daily catch in word count:\")\n",
    "    print(new_words)\n",
    "for line in new_words:   \n",
    "    vocab['white_listed'].add(line.replace(\"'\",\"\").strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0141a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Nong\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wyw_text = 'สวัสดีครับน้อง'\n",
    "print(ts.google(wyw_text))\n",
    "#print(ts._google.language_map)\n",
    "#print(ts.google(wyw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "67b1cbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today's catch % of corpus:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.200344766395417%'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get after when adding in new words\n",
    "print(\"today's catch % of corpus:\")\n",
    "str(100*(percent-prev_percent))+\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3258e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output newly knowns\n",
    "with open(path+\"new_known_thai_lines.txt\",\"w\") as outfile:\n",
    "    for line in list(set(knowns).difference(prev_knowns)):\n",
    "        outfile.write(line+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a9fb3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check. Current vocab size:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1462"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Sanity check. Current vocab size:\")\n",
    "len(vocab['white_listed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "564b37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "to do:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9799280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##INPUT-OUTPUT\n",
    "#vocab list:\n",
    "with open(\"/Users/elyebliss/Desktop/Vocabulary/vocab_dfs/thai_whitelisted.csv\",\"r\") as infile:\n",
    "    whitelisted_lemmas = infile.read()\n",
    "\n",
    "\n",
    "##VARIABLES\n",
    "vocab_all = set()\n",
    "\n",
    "\n",
    "for line in whitelisted_lemmas.split('\\n'):\n",
    "    if len(line) > 0:\n",
    "        \n",
    "        vocab = line.strip()\n",
    "        vocab_all.add(vocab)\n",
    "        \n",
    "len(whitelisted_lemmas.split('\\n'))            \n",
    "#pp.pprint(vocab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e37bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "vocab['white_listed'] = list(vocab_all)\n",
    "vocab['black_listed'] = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
